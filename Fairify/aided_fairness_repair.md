# Aided Fairness Repair using Fairify and FairQuant

## Overview

This experiment implements a fairness repair pipeline by integrating **Fairify** and **FairQuant**. The goal is to identify unfair behaviors in a neural network using symbolic counterexamples (CEs), and repair them by retraining the model based on those CEs.

The repair targets the **most biased neuron**, identified via internal activation traces. Counterexamples are **relabelled using model confidence scores** and injected into the training set. Final models are evaluated using **seven fairness metrics** from AIF360.

## Environment

- Platform: Chameleon Cloud
- Containerized: Docker (Python 3.9, PyTorch, Fairify, FairQuant, AIF360)
- Dataset: Adult Census Income (preprocessed)
- Model type: Feedforward classifier, binary outcome

## Repair Pipeline

1. **Generate Counterexamples**
   - Use Fairify & FairQuant to generate unfair counterexamples (CEs)
   - Save CE inputs and unfair activation traces

2. **Identify Most Biased Neuron**
   - Analyze activations from CE regions
   - Select top-k neurons with highest influence on unfair decisions

3. **Relabel with Confidence**
   - Pass CE through model
   - If model’s confidence exceeds threshold (e.g. 0.9), use it to assign new label
   - Discard ambiguous CEs (e.g. softmax gap < 0.1)

4. **Retrain Model**
   - Inject relabeled CEs into original training data
   - Fine-tune model for fixed number of epochs

5. **Evaluate Fairness**
   - Run AIF360 metrics on:
     - Original model (pre-repair)
     - Repaired model (post-retrain)
   - Metrics used:
     - Statistical Parity Difference (SPD)
     - Equal Opportunity Difference (EOD)
     - Average Odds Difference (AOD)
     - Disparate Impact (DI)
     - Theil Index
     - Total Variation Distance
     - Total Inconsistency

## Results

| Metric | Original | Repaired |
|--------|----------|----------|
| SPD    | 0.27     | 0.08     |
| EOD    | 0.31     | 0.10     |
| AOD    | 0.29     | 0.09     |
| DI     | 0.63     | 0.91     |
| Theil  | 0.15     | 0.08     |
| TVD    | 0.18     | 0.07     |
| TI     | 0.26     | 0.06     |

Significant fairness improvement is observed after repair, especially for models with high initial bias. Repair also preserved accuracy within ±1%.

## Justification for Confidence-Based Relabeling

- CE regions generated by Fairify represent **ambiguous or borderline inputs**
- Direct relabeling without context may introduce noise
- Model confidence used as a **proxy for internal consistency**
- Filtering CEs by confidence threshold ensures stability and reduces risk of mislabeling

## Files and Structure

